{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tsne plots for phrase embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should read more about plotting wordembeddings:\n",
    "http://learningaboutdata.blogspot.de/2014/06/plotting-word-embedding-using-tsne-with.html\n",
    "\n",
    "I am using the barnes-hut python wrapper tsne.\n",
    "The barnes-hut implementation has O(n log_n) complexity (the original algorithm uses O(nÂ²).)\n",
    "\n",
    "moreover I should know about how to render word-label with matplotlib\n",
    "http://stackoverflow.com/questions/22859648/creating-a-wordcloud-with-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hickle\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from bokeh.plotting import figure, HBox, output_file, show, VBox\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.charts import Scatter, output_file, show\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tsne representation and word2vec model\n",
    "penta_emb_tsne = hickle.load('/home/kuhn/Data/models/penta_tsne')\n",
    "penta_model = Word2Vec.load('/home/kuhn/Data/models/pentagram_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of tools to use\n",
    "TOOLS=\"pan,wheel_zoom,box_zoom,reset,previewsave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6540784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasemb_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7eff9632dc90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# give me just the first 100 values....\n",
    "pyplot.scatter(phrasemb_plot[:100, 0], phrasemb_plot[:100, 1], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this works out pretty nice, still missing word-labels though \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408799, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the dimensionality of the array:\n",
    "phrasemb_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7effac33acd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyplot.scatter(phrasemb_plot[1, 0], phrasemb_plot[1, 1], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I need a csv file with xy coords of each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Labelling Words to the Scatterplot Coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at a snippet of the tutorial on Jane Austen's Pride and Prejude with Word Embedding (thx to Arne for the advice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```Python\n",
    "# The wrapper function that runs everything, writes files, and returns useful things.\n",
    "def run_all(tags=['NN'], filepref='data/pride_NN'):\n",
    "    \n",
    "    # notice here i require at least 2 uses of each word in the corpus - reduces noise\n",
    "    \n",
    "    # uncomment the version of the model you want to try: tag limited, or all words.\n",
    "    #model = gensim.models.Word2Vec(MySentences('books', tags=tags), min_count=2, size=200, workers=2)\n",
    "    model = gensim.models.Word2Vec(DirOfPlainTextCorpus('books'), min_count=3, workers=2)\n",
    "    model.save(filepref + '_model_austen_allwordsmin3')\n",
    "    \n",
    "    # if you want to save time and use a saved file, comment out the above and uncomment this with right path\n",
    "    #model = gensim.models.Word2Vec.load('data/pride_NNPRP_model_austen_all')\n",
    "    \n",
    "    # does the text tagging and word replacement\n",
    "    print tags\n",
    "    datadict = build_dict_write_file(model, filepref + '_labeled.txt', filepref + '_data.json', tags=tags)\n",
    "    \n",
    "    # tsne input files part\n",
    "    make_score_files(model, datadict, filepref)\n",
    "    \n",
    "    # the actual tsne graph bit\n",
    "    X = np.loadtxt(filepref + \"_scores.csv\")\n",
    "    labels = np.genfromtxt(filepref + \"_words.csv\", dtype=str)\n",
    "    Y = tsne.tsne(X, 2, 50, 20.0)   # see tsne.py in repo\n",
    "    do_tsne_files(filepref + '_coords.tsv', Y, labels, datadict, axis_off=True)\n",
    "    \n",
    "    return Y, labels, datadict, model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, the w2v model ist trained - a goal we already achieved. the model is then saved to a file.\n",
    "the 'datadict' line. Section *#the actual tsne graph bit* pretty much contains the info we need.\n",
    "the line\n",
    "```python\n",
    "labels = np.genfromtxt(filepref + \"_words.csv\", dtype=str)\n",
    "```\n",
    "\n",
    "takes a csv file that contains the vocabulary of the corpus and konverts it to a numpy array.\n",
    "\n",
    "We already have calculated the tsne representation of our phrase embedding so it is important to take a look at this line\n",
    "```python\n",
    "do_tsne_files(filepref + '_coords.tsv', Y, labels, datadict, axis_off=True)\n",
    "```\n",
    "the corresponding method is defined below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "\n",
    "# this is a function you can call independently with output from your run-all run, to jigger with details if you want.\n",
    "def do_tsne_files(coordsfilename, Y, labels, datadict, axis_off=True):\n",
    "    \"\"\" Makes the tsne grah file and writes out the coords for the UI. \"\"\"\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    if axis_off:\n",
    "        plt.axis('off')   # only turn off after checking the axis min/max\n",
    "    plt.scatter(Y[:,0], Y[:,1], s=10, color='gray', alpha=0.2)\n",
    "    print \"X and Y dims \", plt.axis()\n",
    "    with open(coordsfilename, 'w') as handle1:\n",
    "        handle1.write('word\\tx\\ty\\tnearest\\n')\n",
    "        for label, x, y in zip(labels, Y[:, 0], Y[:, 1]):\n",
    "            score = datadict[label]['score']\n",
    "            handle1.write('\\t'.join([label, str(x), str(y), str(score)]) + '\\n')\n",
    "            #plt.text(x, y, label, size=8, alpha=0.5)\n",
    "    print \"wrote out\", coordsfilename\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a list all indexed words of the model via the index2word attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'angeforderten_Gerichtskosten'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penta_model.index2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use numpy.array to turn the list to a numpyarray.\n",
    "http://docs.scipy.org/doc/numpy/user/basics.creation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = numpy.array(penta_model.index2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now modifying do_tsne_files to fit our needs (w/o score parameter). using codecs to deal with unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def do_tsne_files(coordsfilename, Y, labels, axis_off=True):\n",
    "    \"\"\" Makes the tsne grah file and writes out the coords for the UI. \"\"\"\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    if axis_off:\n",
    "        plt.axis('off')   # only turn off after checking the axis min/max\n",
    "    plt.scatter(Y[:,0], Y[:,1], s=10, color='gray', alpha=0.2)\n",
    "    print \"X and Y dims \", plt.axis()\n",
    "    with codecs.open(coordsfilename, mode='w', encoding='utf-8' ) as handle1:\n",
    "        handle1.write('word\\tx\\ty\\n')\n",
    "        for label, x, y in zip(labels, Y[:, 0], Y[:, 1]):\n",
    "            \n",
    "            handle1.write('\\t'.join([label, str(x), str(y)]) + '\\n')\n",
    "            #plt.text(x, y, label, size=8, alpha=0.5)\n",
    "    print \"wrote out\", coordsfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y dims  (-4.0, 4.0, -4.0, 4.0)\n",
      "wrote out /tmp/misc.tsv\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "do_tsne_files('/tmp/misc.tsv', penta_emb_tsne, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "somehow we expected the german language to spoil the party. lets deal with numpy to unicode tasks\n",
    "http://stackoverflow.com/questions/16037824/how-to-convert-numpy-object-array-into-str-unicode-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
